a1.sources = so
a1.sinks = si
a1.channels = ch

a1.sources.so.type = netcat
a1.sources.so.bind = 127.0.0.1
a1.sources.so.port = 25001

a1.sinks.si.type = "org.apache.flume.kafka.KafkaSink"
a1.sinks.si.topic = "ods_mall_log"
a1.sinks.si.brokerList = "192.168.45.13:9092"

a1.channels.ch.type = memory
a1.sinks.si.channels = ch
a1.sources.so.channels = ch






a2.sources = s1
a2.sinks = k1
a2.channels = c1

a2.sources.s1.type = netcat
a2.sources.s1.bind = 127.0.0.1
a2.sources.s1.port = 25001

a2.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a2.sinks.k1.topic = ods_mall_log
a2.sinks.k1.brokerList = 192.168.45.13:9092

a2.channels.c1.type = memory

a2.sources.s1.channels = c1
a2.sinks.k1.channel = c1


在Master节点进入到maxwell-1.29.0的解压后目录下（在/opt/module），
配置相关文件并启动，
读取MySQL数据的binlog日志（mysql的binlog相关配置已完毕）到Kafka的Topic中（Topic名称为ods_mall_data，分区数为4）。
将order_master和order_detail中的数据创建为fact_order_master和fact_order_detail，
存储在Kafka的topic为ods_mall_data中，使用Kafka自带的消费者消费ods_mall_data（Topic）中的数据，查看前2条数据的结果；



$"order_sn",
$"customer_id",
$"hipping_user",
$"province",
$"city",
$"address",
$"order_source",
$"payment_method",
$"order_money",
$"district_money",
$"shipping_money",
$"payment_money",
$"shipping_sn",
$"create_time",
$"hipping_time",
$"pay_time",
$"receive_time",
$"order_status",
$"invoice_title",
$"modified_time",



$"order_detail_id",
$"order_sn",
$"product_id",
$"product_name",
$"product_nct",
$"product_price",
$"average_cost",
$"weight",
$"fee_money",
$"w_id",
$"create_time",
$"modified_time",